---
Author: Thomas Verliefde
Date: '2019-07-10'
Output: html_document
Title: Analyses AmbDiff
editor_options:
  chunk_output_type: console
version: '0.3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
# load("20190411.RData")
# save.image(file="20190411.RData")
```

```{r libraries, include=FALSE}
lapply(
  c("plyr","dplyr","tidyr","ggplot2","readxl","readr","lme4","afex","lmerTest",
    "emmeans","purrr","magrittr","cowplot","stringr","rstan","mvtnorm"),
  require,
  character.only = T
)
```

#################
# Data Wrangling 
#################

```{r import, cache=FALSE, message=FALSE}

temp <- tempdir()
RAW <- "Data_AmbDiff.zip" %>% {
  ldply(
    .data = unzip(.,list=T) %$%
      grep("(.csv)$",Name,value=TRUE),
    .fun = function(x) unzip(.,files=x,exdir=temp) %>%
      read_csv(col_types = rep("?",1259) %>% paste0(collapse=""))
  ) %>% as_tibble %>% arrange(Subject)
} 
rm(temp)

```

```{r !, options}

# utils::View(df_raw)
seq(1,80) %in% df_raw$Subject %>% not %>% which
"Data_AmbDiff.zip" %>% unzip(list=T) %>% arrange(Date) %>%
  filter(grepl("(.csv)$",.$Name))

```

Participant 48's data is missing ...

Comments from during data collection:
*Subject 20 was remarkably quick
*Subject 44 stated to already know the experiment - will be excluded
*Subject 59 stated to already know the experiment - will be excluded
*Subject 60 had to restart the experiment once, at the start

```{r df, options}

df <- RAW %>%
  select(
    grep("(Primes$)|(Trials$)|(^practice)",colnames(.),invert=TRUE)
  )%>%
  gather(
    key = "key",
    value = "value",
    grep("(^experiment)",colnames(.))
  ) %>%
  tidyr::extract(
    .,
    key,
    c("Block","Trial","key"),
    "(\\d+)_(\\d+)_(\\D+)$"
  ) %>%
  mutate(
    Subject = Subject %>% as.factor,
    key = key %>% str_to_title
  ) %>%
  spread(
    key,
    value
  ) %>%
  group_by(
    Subject
  ) %>%
  transmute(
    Key = Key %>% factor(levels=c("Ypos","Yneg")),
    Age = Age %>% as.numeric,
    Gender = Gender %>%
      recode(
        "weiblich" = "Female",
        "männlisch" = "Male",
        .default = "Other"
      ) %>% factor(levels=c("Female","Male","Other")),
    Language = Language %>%
      recode(
        "Deutsch" = "German",
        "Sonstiges" = "Other"
      ) %>% factor(levels=c("German","Other")),
    Handedness = Handedness %>%
      recode(
        "rechts" = "Right",
        "links" = "Left",
        "beide" = "Both"
      ) %>% factor(levels = c("Right","Left","Both")),
    Block = Block %>%
      recode(
        "0" = "First",
        "1" = "Second"
      ) %>%
      factor(levels=c("First","Second")),
    Trial = Trial %>%
      as.numeric,
    Response = case_when(
      Key == "Ypos" & Answer == "Y" ~ "Positive",
      Key == "Yneg" & Answer == "OemMinus" ~ "Positive",
      Key == "Ypos" & Answer == "OemMinus" ~ "Negative",
      Key == "Yneg" & Answer == "Y" ~ "Negative"
    ) %>%
      factor(levels = c("Positive","Negative")),
    primeWord = Prime %>% as.factor,
    primeValence = Primecat %>%
      as.factor %>%
      recode(
        "0" = "Ambivalent",
        "1" = "Positive",
        "2" = "Negative",
        "3" = "Neutral"
      ),
    targetWord = Target %>% as.factor,
    targetValence = Targetcat %>%
      as.factor %>%
      recode(
        "0" = "Positive",
        "1" = "Negative"
      ),
    Congruency = case_when(
      equals(primeValence %>% as.character,targetValence %>% as.character) ~ "Congruent",
      primeValence %>% as.character %>% is_in(c("Positive","Negative")) ~ "Incongruent",
      TRUE ~ primeValence %>% as.character
    ) %>% factor(levels=c("Ambivalent","Congruent","Incongruent","Neutral")),
    RT = Time %>% as.numeric,
    logRT = RT %>% log,
    Correct = Response == targetValence,
    Accuracy = mean(Correct),
    latencyIncl = (RT >= 300 & RT <= 3000),
    accIncl = (1 - mean(latencyIncl | Correct)) < 0.83,
    ruleIncl = (Subject %in% c(44,59,60)) %>% not,
    subjIncl = accIncl & ruleIncl,
    trialIncl = Correct & latencyIncl,
    Inclusion = trialIncl & subjIncl,
    diffInclusion = latencyIncl & subjIncl
  ) %>% ungroup %>%
  arrange(Subject,Block,Trial)

```

```{r dfDemo, options}

dfDemo <- df %>%
  distinct(Subject,Key,Age,Gender,Language,Handedness,Accuracy,accIncl,ruleIncl,subjIncl)

```

################
# Demographics 
################

```{r subj excl, options}

dfDemo %>%
  filter(accIncl %>% not) %>%
  nrow %>%
  paste("participants were excluded due to extremes in accuracy or latency.")

dfDemo %>%
  filter(ruleIncl %>% not) %>%
  nrow %>%
  paste("participants were excluded due to issues during data collection.")
# 2 participants indicated to have already performed the experiment before.
# 1 participant had to restart the program during experimentation.

dfDemo %>%
  filter(subjIncl) %>%
  nrow %>%
  paste("participants were included for the analyses.")

```

```{r trial excl, options}

df %>%
  filter(subjIncl) %$%
  mean(Correct) %>%
  subtract(1,.) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were incorrectly categorised.")

df %>%
  filter(subjIncl) %$%
  mean(latencyIncl) %>%
  subtract(1,.) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were responded to either too quickly (<300ms) or too slowly (>3000ms)")

df %>%
  filter(subjIncl) %$%
  mean(trialIncl) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were ultimately included for hierarchical analyses, based on speed and accuracy.")

df %>%
  filter(subjIncl) %$%
  mean(latencyIncl) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were ultimately included for diffusion analyses, based on speed and accuracy.")

```


############
# Analyses 
############

################
## Hierarchical
################

The main idea here is to test whether the ambivalence deceleration found in previous research (e.g. Berger, Hütter, & Corneille, 2019) is also found here.
For this, we run a mixed model.


```{r Valence Model, options}

afex::set_effects_contrasts()

valFit <- df %>%
  filter(Inclusion) %>%
  mixed(
    logRT ~ primeValence * targetValence * Block + (1|primeWord) + (1|targetWord) + (1|Subject),
    data = .,
    method='S'
  )
valFit

emmValFit <- valFit %>%
  emmeans(~primeValence * targetValence)


contrValFit <- emmValFit %>%
  contrast(method="revpairwise",adjust="none") %>%
  as_tibble %>%
  separate(
    contrast,
    c("primeA","targetA","primeB","targetB")
  ) %>%
  filter(primeB == "Ambivalent" & primeA != "Ambivalent") %>%
  filter(targetA == targetB)

```

```{r Mixed Contrasts, options}

valFit %>%
  emmeans(~Block) %>%
  contrast

valFit %>%
  emmeans(~primeValence * targetValence * Block) %>%
  contrast(method = "trt.vs.ctrl", by=c("Block","targetValence"))

valFit %>%
  emmeans(~primeValence * targetValence) %>%
  contrast(method = "trt.vs.ctrl", by=c("targetValence"))


```

Block Comparison

 contrast      estimate      SE  df z.ratio p.value
 First effect     0.021 0.00178 Inf  11.789 <.0001  ***
 Second effect   -0.021 0.00178 Inf -11.789 <.0001  ***


Prime Comparison by Block & targetValence

Block = First, targetValence = Positive:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.010508 0.0101 Inf -1.044  0.5833 
 Negative - Ambivalent  0.013543 0.0102 Inf  1.328  0.4056 
 Neutral - Ambivalent   0.000555 0.0101 Inf  0.055  0.9989 

Block = First, targetValence = Negative:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.005451 0.0103 Inf -0.531  0.8819 
 Negative - Ambivalent -0.009350 0.0103 Inf -0.911  0.6692 
 Neutral - Ambivalent  -0.012950 0.0102 Inf -1.269  0.4406 

Block = Second, targetValence = Positive:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.036828 0.0100 Inf -3.672  0.0007  ***
 Negative - Ambivalent  0.006738 0.0101 Inf  0.666  0.8154 
 Neutral - Ambivalent  -0.019648 0.0101 Inf -1.948  0.1325 

Block = Second, targetValence = Negative:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent  0.001699 0.0102 Inf  0.167  0.9891 
 Negative - Ambivalent -0.026018 0.0101 Inf -2.573  0.0281  *
 Neutral - Ambivalent  -0.011373 0.0101 Inf -1.124  0.5314


Prime Comparison by targetValence, averaged over Block

targetValence = Positive:
 contrast              estimate      SE  df z.ratio p.value
 Positive - Ambivalent -0.02367 0.00717 Inf -3.300  0.0028  ***
 Negative - Ambivalent  0.01014 0.00725 Inf  1.398  0.3651 
 Neutral - Ambivalent  -0.00955 0.00721 Inf -1.325  0.4073 

targetValence = Negative:
 contrast              estimate      SE  df z.ratio p.value
 Positive - Ambivalent -0.00188 0.00730 Inf -0.257  0.9734 
 Negative - Ambivalent -0.01768 0.00727 Inf -2.431  0.0414  *
 Neutral - Ambivalent  -0.01216 0.00725 Inf -1.677  0.2278 
 
We can replicate the results found previously:
  Ambivalent prime trials have significantly higher latencies in comparison to congruent positive and negative noun prime trials.
  There seems to be no difference otherwise, not for incongruent trials, nor for neutral letter primes.

These results are not found in only the first block, but they are found in the second, and when averaging over blocks.
Further, the results above are computed with the dunnettx method for 3 tests. Leaving out this adjustment, the results stay the same.

```{r emmGraph, options}

ggValFit <- emmValFit %>%
  as_tibble %>%
  transmute(
    RT = emmean %>% exp,
    minRT = asymp.LCL %>% exp,
    maxRT = asymp.UCL %>% exp,
    primeValence = primeValence %>% factor(levels = c("Ambivalent","Positive","Negative","Neutral")),
    targetValence = targetValence %>% factor(levels = c("Positive","Negative")),
    Congruency = case_when(
      equals(primeValence %>% as.character,targetValence %>% as.character) ~ "Congruent",
      TRUE ~ "Other"
      )
  ) %>%
  ggplot(
    aes(y = RT, ymin = minRT, ymax = maxRT, x = primeValence, fill = targetValence, colour = Congruency, size = if_else(Congruency == "Congruent",1.1,0))
  ) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(position = position_dodge2(padding=.8),colour="black",size=.5) +
  labs(x = "Prime Valence", y = "Reaction Times (ms)", fill = "Target\nValence") +
  guides(colour=FALSE,size=FALSE) +
  scale_colour_manual(values=c("black","white")) +
  scale_size_identity() +
  theme(
    plot.margin = unit(c(1.4,0.4,0.4,0.4),"cm")
  ) +
  geom_segment(
    data = tibble(
      x = c(.75,1.25),
      xend = c(1.75,3.25),
      y = c(660,700),
      yend = c(660,700)
    ),
    aes(x=x,y=y,xend=xend,yend=yend,size=.75),
    inherit.aes = FALSE
  ) +
  geom_label(
    data = contrValFit %>% filter(p.value < .05),
    aes(
      x = c(1.25,2.25),
      y = c(660,700),
      label = p.value %>% sprintf("%.3f",.)
    ),
    inherit.aes = FALSE
  )
ggValFit

ggsave("valEmm.svg",plot = ggValFit,device = "svg")


```

Comparisons with neutral primes did not show differences, except for incongruent negative trials.

```{r further contrasts, options}

emmValFit %>% contrast(method = "trt.vs.ctrlk", by=c("targetValence"))

```


```{r Congruency Model, options}

afex::set_effects_contrasts()

congrFit <- df %>%
  filter(Inclusion) %>%
  mixed(
    logRT ~ Congruency * Block + (1|primeWord) + (1|targetWord) + (1|Subject),
    data = .,
    method='S'
  )
congrFit

emmCongrFit <- congrFit %>%
  emmeans(~Congruency)


contrCongrFit <- emmCongrFit %>%
  contrast(method="trt.vs.ctrl",adjust="none") %>%
  as_tibble %>%
  separate(
    contrast,
    c("primeA","primeB")
  )

congrFit %>%
  emmeans(~Block) %>%
  contrast

```

Comparing directly on congruency, the same results are found, with ambivalent trials being clearly slower than congruent trials.
Note that here there seems to be a difference between neutral and ambivalent primes, indicating ambivalent primes being slower.
The inconsistency between this model and the previous could reflect the difficulty of consistently finding this effect (e.g. Berger, Hütter, & Corneille, 2019).

```{r label, options}

ggCongrFit <- emmCongrFit %>%
  as_tibble %>%
  transmute(
    RT = emmean %>% exp,
    minRT = asymp.LCL %>% exp,
    maxRT = asymp.UCL %>% exp,
    Congruency = Congruency %>% factor(levels = c("Ambivalent","Congruent","Incongruent","Neutral"))
  ) %>%
  ggplot(
    aes(y = RT, ymin = minRT, ymax = maxRT, x = Congruency, fill = Congruency)
  ) +
  geom_col(position = position_dodge2(),width = .8) +
  geom_errorbar(width=.3) +
  labs(x = "Prime Conditions", y = "Reaction Times (ms)") +
  scale_fill_manual(values=c("orange","limegreen","red2","grey50")) +
  guides(fill=FALSE) +
  theme(
    plot.margin = unit(c(1.4,0.4,0.4,0.4),"cm")
  ) +
  geom_segment(
    data = tibble(
      x = c(1,1),
      xend = c(2,4),
      y = c(660,700),
      yend = c(660,700)
    ),
    aes(x=x,y=y,xend=xend,yend=yend,size=1),
    inherit.aes = FALSE
  ) +
  scale_size_identity() +
  geom_label(
    data = contrCongrFit %>% filter(p.value < .05),
    aes(
      x = c(1.5,2.5),
      y = c(660,700),
      label = p.value %>% sprintf("%.4f",.)
    ),
    inherit.aes = FALSE
  )
ggCongrFit

ggsave("congrEmm.svg",plot = ggCongrFit,device = "svg")

```


###############
## Diffusion 
###############

Voss et al. 2013 - Cognitive Processses in Associative and Categorical Priming: A Diffusion Model Analysis

Parameters:
  v   drift rate
  a   thershold distance
  z   starting point
  t0  non-decisional processes
  sx  trial-to-trial variability
  
  d = t0lower - t0upper
  t0lower  non-decisional processes for lower threshold
  t0upper  non-decisional processes for upper threshold

Kolmogorov-Smirnov Statistic for optimization

The diffusion model was fitted to the individual response time distributions (using fast-dm).
In all analyses, data were collapsed across target types (i.e. positive and negative).
The upper threshold was assigned to correct responses (~ positive drift rates indicate more efficient processing).
The d-parameter maps the difference between positions of RT-distributions for correct responses and error responses.
If primes influence the speed of response execution, larger values of d will emerge for congruent primes, and smaller for incongruent primes.

Due to a low number of errors, it was not possible to estimate a model with free starting point and with separate non-decisional parameters for correct and incorrect responses.
For the same reason, the distance from the starting point to the lower threshold can also not be estimated with sufficient accuracy.
We therefore decided to fix z to a/2 in all analyses. We decided to estimate separate t0 parameters, rather than differences in starting point.

Drift rate (v), response-time constant (t0), and response tendency parameter (d) were estimated separately for different prime types (i.e., congruent, incongruent, or neutral) while the remaining parameters (a, sz, sv, and st) were assumed constant across conditions.


Overview and Hypotheses

The drift rate (v) maps effects such as differences in speed of target identification, or accessibility of semantic target features.
The response-time constant (t0) captures activation and execution of the correct motor program.

  We assume that primes lead to a pre-activation of associated target concepts and their semantic attributes which should have an impact on the efficiency of the decision process. Information from pre-activated targets should be more readily accessible, that is, the target concept and semantic target attributes should be processed and identified more readily. Therefore, we expect larger drift rates (v) for targets associated compared to non-associated primes. Such associative priming effects are expected to be largerly independent of the task that is to be performed on the targets as long as the task requires lexical or semantic target processing.
  As elaborated above, we expect that all types of response priming designs are primarily based on Stroop-like interference processes. We assume that such interference processes operate at the stage of response execution. According to this account, a prime from the same category as a following target might pre-activate the corresponding motor-response program. In this case, the primed response can be executed faster. IF the prime belongs to the alternative response category, the execution of the correct response to the target should be slowed down due to response interference. Since these effects operate independently of the identification and classification of the target, they will be mapped onto the non-decisional RT component of the diffusion model. The non-decisional component shoulde either be generally reduced by a categorical match between prime and target (lower values on t0), or, more specifically, the primes should reduce/increase the time that is need in order to execute the matching/non-matching response, leading to positive/negative values for d in case of congruent/incongruent primes
  Another possibility that cannot be ruled out a priori is that response priming effects influence the response selection process by biasing the deciison process in the direction of the prime category. Such an effect would be mapped by the diffusion model on the starting point (z). As already mentioned above, we cannot estimate priming effects on t0, d, and z simultaneously (Voss et al. 2010). We therefore decided to estimate models with two non-decisional components (t0 and d) in which the starting point was fixed, but we also conducted additional analyses in which the starting point was estimated freely.

##############################################################
### Experiment 1b: affective priming in the evaluation task
##############################################################

For experiment 1b, 48 positive and 48 negative German adjectives were used as targets. 48 positive and 48 negative nouns were used as primes. Prime-target pairs were constructed by assigning one congruent prime, one incongruent prime, and one neutral letter string prime to each target. Each prime word was used as congruent prime for one target and as incongruent prime for another target. Pairings were identical for all participants.
The only theoretically relevant factor was prime type: affectively congruent, affectively incongruent, neutral.

Data pre-treatment.
  Speed instructions and rewarding of speeded responses were used to evoke a high error rate. However, the logic of payoffs seemed to have encouraged participants to make fast guesses in some trials to maximize the chance of winning the performance related reward. Accordingly, there was a large amount of fast outlier latencies which can bias parameter estimates from a diffusion model analysis. Therefore, a three-step procedure to identify outliers was performed: First, all latencies below 200ms were excluded. Second, latencies were eliminated starting from the lower edge of the individual RT distributions until the number of removed correct responses exceeded the number of removed error responses by 3. This was done to exclude latencies that were based on pure guessing. Third, from the remaining individual latency distributions values below the first quartile minus 1.5 inter-quartile-ranges were eliminated, and similar for values above the third quartiel plus 1.5 inter-quartile-ranges. This procedure led to an exclusion of 7.3% of trials.
  
Contrast between congruent and incongruent trials was significant.
Error rates did not differe significantly between congruent and incongruent trials.

The three parameters that were allowed to vary between prime types (v, t0, and d) were entered in separate repeated measurement ANOVAs.
In experiment 1b, prime type did not influence the drift rates. However, there was a significant effect on the RT constant (t0). Planned contrasts revealed that the non-decisional processes were faster in trials with congruent primes compared to trials with incongruent primes. The analysis of the d-paramtere failed to reach statistical significance.

Fit-indices (p) provided by fast-dm are the probabilities of the Kolmogorov-Smirnov-statistic, that is, they are measures for deviances of the empirical from the predicted RT distributions. In our case, the presented p values represent the product of the three different p values based on the comparison of empirical and predicted distributions for the three priming conditions. Although p cannot be interpreted as the exact probability of a statistical test it is nonetheless obvious that the values are very close to 1, indicating that the empirical distributions are reproduced very closely by the predicted distributions.

In experiment 1b the evalutation task was used to demonstrate an affective priming effect.
Affective priming effects with the evaluative decision task were based on differences in the non-decisional components (t0), indicating that response execution in the evaluation task was faster following congruent than incongruent primes. This finding fits with the response facilitation/interference account of affective priming effects in the evaluation task. According to this idea, the processing of the prime stimulus automatically pre-activates the corresponding response, which then either facilitates the execution of the target response in case of a match (congruent target), or interferes with the execution of the target response in case of a mismatch (incongruent target). The fact that the effect was mapped on t0 in the present experiment indicates that response compatibility effects mainly affected the execution of correct responses. The lack of an effect on the d parameter indicates that the response compatibility effects were not reversed for error responses. We attribute this null finding at least in part to the fact that the RT component for error responses cannot be estimated very reliably due to the small number of errors.

Experiment 1b is not the first study that reports evidence for a response competition acocunt of affective priming. The new aspect of our study is that it porvided direct evidence for response competition effects in affective priming within the evaluation task.
Processing of a valent prime did not have an influence on the drift rate for targets, indicating affective congruency does not facilitate target processing. Affective congruency effects in the evaluation task thus have to be explained differently. The diffusion model analyses suggest that the basis of the effect lies in extra-decisional components of response facilitation and interference.


#################################################################
### Experiment 2a: affective congruency of prime-target pairs.
#################################################################

Experiment 2 followed Experimental 1b in procedure, experimental and data treatment-wise.
Similarly, in experiment 2a, evaluation latencies from affectively congruent trials were shorter than latencies from incongruent trials.
In contrast, error rates were reduced in affective congruent trials, compared to trials with affectively incongruent trials.

Drift rate (v), RT-constant (t0), and response-execution bias parameter (d) were entered in separate repeated measurement ANOVAs.
Results revealed a main effect of congruency on t0¨, indicating faster response execution in affectively congruent trials. Effects on the execution bias parameter d revealed that congruency had an opposite influence on RT constants of correct and error responses. Conforming to our expectations, negative values of d (indicating a delay of correct responses) emerged in affectively incongruent trials. Althoguh the drift rate is numerically larger for congruent compared to incongruent paris, this effect is not significant.
Data were reanalyzed with a diffusion model in which d was fixed to 0 and z was estimated for all conditions. Results revealed shorter non-decisional times (t0) for congruency, with no other effects.


```{r Contrast Congruent - Incongruent, options}

emmCongrFit %>%
  contrast(method="pairwise",exclude=c(1,4))

```

Structure for fast-dm:
  response -> 1 vs 0
  latency -> seconds

Each line is data from 1 trial
space or tab separated


################
### Diff Model
################

```{r Data Diffusion, options}

outDiff <- df %>%
  filter(diffInclusion) %>%
  select(Subject,Block, Trial, primeValence, targetValence, Congruency, Response, Correct, RT) %>%
  mutate(
    Block = Block %>%
      recode(
        "First" = 1,
        "Second" = 2
      ),
    primeValence = primeValence %>%
      recode(
        "Positive" = 0,
        "Negative" = 1,
        "Neutral" = 2,
        "Ambivalent" = 3
      ),
    targetValence = targetValence %>%
      recode(
        "Positive" = 0,
        "Negative" = 1
      ),
    Congruency = Congruency %>%
      recode(
        "Congruent" = 0,
        "Incongruent" = 1,
        "Neutral" = 2,
        "Ambivalent" = 3
      ),
    Response = Response %>%
      recode(
        "Positive" = 0,
        "Negative" = 1
      ),
    Correct = Correct %>% as.numeric
  )

```

Note, the diffusion parameter estimation is performed using fast-DM outside of R.
For this, 

```{r Write Diffusion, options}

outDiff %>%
  d_ply(
    ~ Subject,
    function(x) {
      write(
        "# Block Trial primeValence targetValence Congruency Response Correct RT",
        paste0("fastDM/Data/dat",x$Subject %>% unique,".txt")
      )
      write.table(
        x %>% select(-Subject),
        paste0("fastDM/Data/dat",x$Subject %>% unique,".txt"),
        sep = " ",
        append = TRUE,
        row.names=FALSE,
        quote=FALSE,
        col.names=FALSE
      )
    }
  )

```

```{r Write Control, options}

"method ks
# using Kolmogorov-Smirnov statistic
set zr 0.5
set p 0
# fixing z relative to a at 0.5
# a, sz, sv, st assumed constant across conditions for parsimony
depends v Congruency
depends d Congruency
depends t0 Congruency
# allowing v, d, & t0 to vary between conditions
format * * * * Congruency * RESPONSE TIME
# response is correct/false (1/0)
load Data\\dat*.txt
save Results\\sv0\\*.par
log parameterFree.lst" %>%
  cat(
    file = "fastDM/model_ks_congr_corr.ctl"
  )

"method ks
# using Kolmogorov-Smirnov statistic
set zr 0.5
set sv 0
set szr 0
set st0 0
set p 0
# fixing z relative to a at 0.5
# a, sz, sv, st assumed constant across conditions for parsimony and computational speed, additionally, only a will be estimated
depends v Congruency
depends d Congruency
depends t0 Congruency
# allowing v, d, & t0 to vary between conditions
format * * * * Congruency * RESPONSE TIME
# response is correct/false (1/0)
load Data\\dat*.txt
save Results\\constrained\\*.par
log parameterConstr.lst" %>%
  cat(
    file = "fastDM/model_ks_congr_corrConstr.ctl"
  )


```

The parameter estimation for the diffusion model was computed outside R, using fast-dm.exe within a cmd console.
The command executed was: "fast-dm.exe model" with model being one of the .ctl model files above.
Note that this command was executed within the fastDM folder, so that the data is correctly loaded.
The code below should do the same from within R, but sadly does not seem to output the progress, making the slow process quite difficult to overview and follow.

```{r PowerShell, options}

# shell("cd fastDM; .\\fast-dm.exe .\\model_ks_congr_corr.ctl",shell = "PowerShell", intern=TRUE)

# shell("cd fastDM; .\\fast-dm.exe .\\model_ks_congr_corrConstr.ctl",shell="PowerShell",intern=TRUE)

```


#########################
### Data Wrangling
#########################


```{r import & wrangling, options}

dfDiff01 <- "fastDM/parameter.lst" %>%
  read.table %>%
  gather("key","Value",matches("_")) %>%
  separate(key,c("Parameter","Congruency"),sep="_") %>%
  mutate(
     Congruency = Congruency %>%
      recode(
        "0" = "Congruent",
        "1" = "Incongruent",
        "2" = "Neutral",
        "3" = "Ambivalent"
      ) %>% factor(levels = c("Ambivalent","Congruent","Incongruent","Neutral")),
    Subject = dataset %>% factor,
    Value = Value %>% as.numeric
  ) %>%
  select(Subject,everything(),-dataset) %>%
  group_by(Parameter) %>%
  mutate(zValue = Value %>% scale) %>%
  ungroup %>%
  arrange(Subject,Parameter,Congruency)


dfDiff02 <- "fastDM/parameterConstr.lst" %>%
  read.table %>%
  gather("key","Value",matches("_")) %>%
  separate(key,c("Parameter","Congruency"),sep="_") %>%
  mutate(
    Congruency = Congruency %>%
      recode(
        "0" = "Congruent",
        "1" = "Incongruent",
        "2" = "Neutral",
        "3" = "Ambivalent"
      ) %>% factor(levels = c("Ambivalent","Congruent","Incongruent","Neutral")),
    Subject = dataset %>% factor,
    Value = Value %>% as.numeric
  ) %>%
  select(Subject,everything(),-dataset) %>%
  group_by(Parameter) %>%
  mutate(zValue = Value %>% scale) %>%
  ungroup %>%
  arrange(Subject,Parameter,Congruency)
  

```

Explanations:
  a, szr, st0 - parameters diffusion, constant over conditions
  penalty - values >0 indicate no valid solution
  fit - method=KS :: p-value from KS test (maximization) | multiple conditions: p-values are multiplied | p is too liberal, since predictions are fit to data
  time - duration of estimation process (seconds) 

Reminder:
        "Congruent" = 0,
        "Incongruent" = 1,
        "Neutral" = 2,
        "Ambivalent" = 3


################
### Model Fit
################

```{r subject parameters, options}

dfDiff01 %>%
  summarize_at(
    vars(a,szr,st0,penalty,fit),
    funs(mean,sd,min,max)
  ) %>%
  gather("key","Value") %>%
  separate(key,c("Parameter","Func")) %>%
  spread(Func,Value) %>%
  select(Parameter,mean,sd,min,max)

dfDiff02 %>%
  summarize_at(
    vars(a,penalty,fit),
    funs(mean,sd,min,max)
  ) %>%
  gather("key","Value") %>%
  separate(key,c("Parameter","Func")) %>%
  spread(Func,Value) %>%
  select(Parameter,mean,sd,min,max)

```

Note that both fit and penalty are 0 for all participants.
Regarding penalty, this is a good sign.
For fit, it is less clear of an indication, both since p-values are multiplied across multiple conditions,
and value is too liberal, since the predictions are fit to the data themselves.
Especially the multiplication of 4 values between 0 and 1 automatically causes the resulted value to be quite small.


```{r condition parameters, options}

dfDiff01 %>%
  group_by(Parameter) %>%
  summarize_at(
    vars(Value,zValue),
    funs(mean,sd,min,max)
  ) %>%
  gather("key","Value",-Parameter) %>%
  separate(key,c("Z","Func")) %>%
  spread(Func,Value) %>%
  mutate(Z = Z == "zValue") %>%
  select(Parameter,Z,mean,sd,min,max)

dfDiff02 %>%
  group_by(Parameter) %>%
  summarize_at(
    vars(Value,zValue),
    funs(mean,sd,min,max)
  ) %>%
  gather("key","Value",-Parameter) %>%
  separate(key,c("Z","Func")) %>%
  spread(Func,Value) %>%
  mutate(Z = Z == "zValue") %>%
  select(Parameter,Z,mean,sd,min,max)

```

```{r dist graph, options}

dfDiff01 %>%
  distinct(Subject,a) %>%
  ggplot(aes(x = a %>% as.numeric)) +
  geom_histogram(binwidth=0.1)

dfDiff01 %>%
  distinct(Subject,st0) %>%
  ggplot(aes(x = st0 %>% as.numeric)) +
  geom_histogram(binwidth=0.1)

dfDiff01 %>%
  distinct(Subject,szr) %>%
  ggplot(aes(x = szr %>% as.numeric)) +
  geom_histogram(binwidth=0.01)

```


```{r dist graph 02, options}

dfDiff02 %>%
  distinct(Subject,a) %>%
  ggplot(aes(x = a %>% as.numeric)) +
  geom_histogram(binwidth=0.1)

curve(dbeta(x,.5,.5))

```

```{r parameter dist graphs, options}

dfDiff01 %>%
  filter(Parameter == "d") %>%
  ggplot(aes(x=zValue)) +
  facet_wrap(~Congruency,scales="free_x",strip.position = "bottom") +
  labs(x = "d Parameter", y = NULL, title = "Distribution of Scaled Parameters by Condition") +
  geom_histogram(binwidth = .1) +
  geom_vline(xintercept = c(-3,3), colour = "red") +
  theme(
    panel.spacing.x = unit(01,"lines"),
    strip.background = element_blank(),
    strip.placement = "outside",
    strip.text = element_text(margin = margin(0.15,0,0.15,0,unit="cm"))
  )

dfDiff01 %>%
  filter(Parameter == "t0") %>%
  ggplot(aes(x=zValue)) +
  facet_wrap(~Congruency,scales="free_x",strip.position = "bottom") +
  labs(x = "t0 Parameter", y = NULL, title = "Distribution of Scaled Parameters by Condition") +
  geom_histogram(binwidth = .1) +
  geom_vline(xintercept = c(-3,3), colour = "red") +
  theme(
    panel.spacing.x = unit(01,"lines"),
    strip.background = element_blank(),
    strip.placement = "outside",
    strip.text = element_text(margin = margin(0.15,0,0.15,0,unit="cm"))
  )

dfDiff01 %>%
  filter(Parameter == "v") %>%
  ggplot(aes(x=zValue)) +
  facet_wrap(~Congruency,scales="free_x",strip.position = "bottom") +
  labs(x = "v Parameter", y = NULL, title = "Distribution of Scaled Parameters by Condition") +
  geom_histogram(binwidth = .1) +
  geom_vline(xintercept = c(-3,3), colour = "red") +
  theme(
    panel.spacing.x = unit(01,"lines"),
    strip.background = element_blank(),
    strip.placement = "outside",
    strip.text = element_text(margin = margin(0.15,0,0.15,0,unit="cm"))
  )

```

```{r parameter dist graphs 02, options}

dfDiff02 %>%
  # filter(Parameter == "d") %>%
  ggplot(aes(x=zValue)) +
  facet_wrap(vars(Parameter,Congruency),scales="free") +
  labs(x = "z-Score", y = NULL, title = "Distribution of Scaled Parameters by Condition") +
  geom_histogram(binwidth = .1) +
  geom_vline(xintercept = c(-3,3), colour = "red") +
  theme(
    panel.spacing.x = unit(01,"lines"),
    strip.background = element_blank(),
    strip.placement = "outside",
    strip.text = element_text(margin = margin(0.15,0,0.15,0,unit="cm")),
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  )

# dfDiff02 %>%
#   ggplot(aes(x=zValue)) +
#   facet_grid(rows = vars(Parameter), cols = vars(Congruency),scales = "free",switch = "y",space="free") +
#   labs(x = "z-Score", y = NULL, title = "Distribution of Scaled Parameters by Condition") +
#   geom_histogram(binwidth = .1) +
#   geom_vline(xintercept = c(-3,3), colour = "red") +
#   theme(
#     panel.spacing.x = unit(01,"lines"),
#     strip.background = element_blank(),
#     strip.placement = "outside",
#     strip.text = element_text(margin = margin(0.15,0,0.15,0,unit="cm")),
#     axis.line.y = element_blank(),
#     axis.ticks.y = element_blank(),
#     axis.text.y = element_blank()
#   )

```


Graphically, we can see a few extreme values for the d-parameter.

```{r Bad fitting Subjects, options}

dfDiff02 %>%
  filter(abs(zValue) >= 3)

```

Subjects 40 has the two extreme values for the d-parameter, and will be excluded.

```{r Exclusion, options}

dfDiff02 %<>%
  mutate(
    Inclusion = !(Subject %in% c(40))
  )

```


################################
#### Assessment of Model Fit
################################

The assessment of model fit with Monto Carlo simulations has the advantage that it leads to a clear criterion for which participants there is a satisfactory model fit. To this end, a critical value for an acceptable fit has to be determined. This critical value will depend on the number of trials, conditions, and parameters, on the estimation procedure, and possibly as well on the observed range of parameter values. Therefore, datasets have to be simulated that match the empirical data sets as closely as possible. It is recommended to draw at least 1000 parameter sets from a multidimensional normal distribution defined by the covariance matrix of the estimated parameter values. This can be accomplished, for example, by the mvtnorm library from the R environment. Then, for each of the 1000 parameter-sets one data set is simulated. The construct-sample tool of fast-dm can be used for this purpose (see below; note that each condition must be simulated separately and combined later into one file). In the next step, simulated parameter sets are entered into a diffusion model analysis with the same settings as used for the analysis of empirical data. From the results, only the fit indices are of importance: The 5% quantile of the distribution of fit indices is then used as critical value to assess fit of empirical results: All datasets performing worse than this 5% criterion should be regarded as bad fitting. If notably more than 5% of datasets show bad fit, it should be questioned critically whether the diffusion model is suitable for the task.

Simulate many data-sets from the diffusion model
- use estimated (or similar) parameter values
- number of conditions and trials matches real data
Fit the diffusion model to the simulated data
- keep all settings identical to the analysis of real data
Extract fit indices
- The 5% quantile (upper/lower, depending on optimization criterion) of distribution of fit indices serves a new criterion of significant deviations
- Models fitting worse than this criterion are to be rejected


conditions: 4
trials: 192
trials/conditions: 48

covariance matrix of the estimated parameter values

```{r Parameters MC-Simulations, options}

dfDiff02 %>%
  select(-zValue) %>%
  spread(Parameter,Value) %>%
  select(
    -c(Subject,penalty,fit,time,method)
  ) %T>% {
    ddply(
      .,
      ~ Congruency,
      function(x) select(x,-Congruency) %>% cov
    ) %>% {
      set_names(
        llply(
          .data = unique(.$Congruency),
          function(x) filter(.,Congruency == x) %>% select(-Congruency) %>% as.matrix
        ),
        unique(.$Congruency)
      )
    } %>%
      assign("covDiff02",.,envir = globalenv())
  } %>%
  dlply(
    ~ Congruency,
    function(x) select(x,-Congruency) %>% colMeans %>% as.matrix %>% t
  ) %>%
  assign("meansDiff02",.,envir=globalenv())

set.seed(20190111)
rmvPars02 <- c("Ambivalent","Congruent","Incongruent","Neutral") %>%
  set_names(
    llply(
      .,
      function(x) {
        rmvnorm(
          n = 250,
          mean = meansDiff02 %>% extract2(x),
          sigma = covDiff02 %>% extract2(x),
          method = "chol"
        ) %>%
          set_colnames(
            meansDiff02 %>%
              extract2(x) %>%
              colnames
          ) %>%
          as_tibble
      }
    ),
  .
)

```

```{r batch file, options}

rmvPars02 %>% {
  set_names(
    llply(
      names(.),
      function(x) {
        extract2(.,x) %>%
          alply(
            .margins = 1,
            function(y) {
              y %$%
                sprintf(
                  "construct-samples.exe -a %f -d %f -t %f -v %f -p %f -N 1 -n 48 -r -o %s",
                  a,d,t=t0,v,p=3,paste0("Sim/constr/",x,"/")
                )
            }
          ) %>% {
            llply(
              names(.),
              function(z) {
                extract2(.,z) %>%
                  paste0(z,".sim")
              }
            )
          }
      }
    ),names(.)
  )
} %>% unlist %>%
  write_lines(
    path = "fastDM/constrSim.cmd"
  )

cmdPars01 %>%
  write_lines(
    path = "fastDM/constrSim.cmd"
  )

```

This batch file was then executed via a cmd in the fastDM folder.

```{r sims, options}

simDiff02 <- c("Ambivalent","Congruent","Incongruent","Neutral") %>% 
  ldply(
    function(x) {
      list.files(paste0("fastDM/Sim/constr/",x),full.names=TRUE) %>%
        ldply(
          function(y) {
            read.table(y) %>%
              mutate(Subject = gsub("\\D","",y) %>% as.numeric)
          }
        ) %>%
        mutate(Congruency = x)
    }
  )

"method ks
# using Kolmogorov-Smirnov statistic
set zr 0.5
set sv 0
set szr 0
set st0 0
set p 0
# fixing z relative to a at 0.5
# a, sz, sv, st assumed constant across conditions for parsimony and computational speed, additionally, only a will be estimated
depends v Congruency
depends d Congruency
depends t0 Congruency
# allowing v, d, & t0 to vary between conditions
format RESPONSE TIME Congruency
# response is correct/false (1/0)
load Sim\\constr\\Combined\\dat*.txt
save Sim\\constr\\Results*.par
log parameterConstr.lst" %>%
  cat(
    file = "fastDM/model_ks_congr_corrSims.ctl"
  )

simDiff02 %>%
  d_ply(
    ~ Subject,
    function(x) {
      write(
        "# Response RT Congruency",
        paste0("fastDM/Sim/constr/Combined/dat",x$Subject %>% unique,".txt")
      )
      write.table(
        x %>% select(-Subject),
        paste0("fastDM/Sim/constr/Combined/dat",x$Subject %>% unique,".txt"),
        sep = " ",
        append = TRUE,
        row.names=FALSE,
        quote=FALSE,
        col.names=FALSE
      )
    }
  )

```

```{r label, options}

simDiff02 %>%
  count(Subject,V1,Congruency) %>%
  filter(n != 48)

```

#########################
### Parameter Analyses
#########################

##########################################################################
#### First model - with estimates for inter-trial z and t0 variability
##########################################################################

```{r model, options}

afex::set_effects_contrasts()

lapply(
  c("d","t0","v"),
  function(x) {
    assign(paste0("Fit01_",x),
      dfDiff01 %>%
        filter(Parameter == x) %>%
        mixed(
          Value ~ Congruency + (1|Subject),
          data = .,
          method = "KR",
          test_intercept = TRUE
        ),
      envir = globalenv()
    )
  }
)

```

```{r emmeans & contrasts, options}

Fit01_d %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

Fit01_t0 %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

Fit01_v %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

```


```{r ANOVA, options}

dfDiff01 %>%
  filter(Parameter == "d") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

dfDiff01 %>%
  filter(Parameter == "t0") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

dfDiff01 %>%
  filter(Parameter == "v") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

```

#########################################################
#### Second Model - fixed inter trial variabilities to 0
#########################################################

```{r model, options}

afex::set_effects_contrasts()
lapply(
  c("d","t0","v"),
  function(x) {
    assign(paste0("Fit02_",x),
      dfDiff02 %>%
        filter(Inclusion) %>%
        filter(Parameter == x) %>%
        mixed(
          Value ~ Congruency + (1|Subject),
          data = .,
          method = "KR",
          test_intercept = TRUE
        ),
      envir = globalenv()
    )
  }
)

```

```{r emmeans & contrasts, options}

Fit02_d %>%
  emmeans(~Congruency)

Fit02_t0 %>%
  emmeans(~Congruency)

Fit02_v %>%
  emmeans(~Congruency)

Fit02_d %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

Fit02_t0 %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

Fit02_v %>%
  emmeans(~Congruency) %>%
  contrast(method="trt.vs.ctrl",adjust="none")

Fit02_d %>%
  emmeans(~Congruency) %>%
  contrast(method="pairwise",include = c("Congruent","Incongruent"),adjust="none")

Fit02_t0 %>%
  emmeans(~Congruency) %>%
  contrast(method="pairwise",include = c("Congruent","Incongruent"),adjust="none")

Fit02_v %>%
  emmeans(~Congruency) %>%
  contrast(method="pairwise",include = c("Congruent","Incongruent"),adjust="none")

```


```{r ANOVA, options}

dfDiff02 %>%
  filter(Inclusion) %>%
  filter(Parameter == "d") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

dfDiff02 %>%
  filter(Inclusion) %>%
  filter(Parameter == "t0") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

dfDiff02 %>%
  filter(Inclusion) %>%
  filter(Parameter == "v") %>%
  aov(
    Value ~ Congruency,
    data=.
  ) %>% summary

```




##################
### STAN Example
##################

```{r STAN, options}

# options(mc.cores = parallel::detectCores())

pkgbuild::check_rtools(debug=TRUE)

rstan_options(auto_write = TRUE)
# 
# cat("\nCXX14FLAGS=-O3 -march=native",
#     "CXX14 = g++ -m$(WIN) -std=c++1y",
#     "CXX11FLAGS=-O3 -march=native",
#     # file = M,
#     sep = "\n", append = TRUE)


# Sys.setenv(LOCAL_CPPFLAGS = '-march=native')

```

```{r 8 Schools, options}

# model file

"data {
  int<lower=0> J;
  real y[J];
  real<lower=0> sigma[J];
}
parameters {
  real mu;
  real<lower=0> tau;
  vector[J] eta;
}
transformed parameters {
  vector[J] theta = mu + tau * eta;
}
model {
  target += normal_lpdf(eta | 0, 1);
  target += normal_lpdf(y | theta, sigma);
}
" %>%
  cat(file="STAN/8schools.stan")

# data list

schools_dat <- list(
  J = 8,
  y = c(28,8,-3,7,-1,1,18,12),
  sigma = c(15,10,16,11,9,11,10,18)
  )

```

```{r running STAN, options}

fit <- stan(
  "STAN/8schools.stan",
  data = schools_dat,
  iter = 2000,
  warmup = 1000,
  chains = 4,
  cores=1,
  thin = 1,
  init = "random",
  verbose = TRUE
  )

```

```{r label, options}

print(fit)

plot(fit)

pairs(fit, pars = c("mu","tau", "lp__")) # lp__ is the log-posterior

la <- rstan::extract(fit, permuted=TRUE)

mu <- la$mu

a <- rstan::extract(fit, permuted=FALSE)

a2 <- as.array(fit)

m <- as.matrix(fit)

d <- as.data.frame(fit)

```

####################
### STAN Diffusion
####################

There are packages handling wiener distribution sampling (RWiener, in combination with brms and stan), but it seems that these implementations do not allow for estimation of differences in speed of response execution (d = tlower - tupper; Voss, Voss, & Klauer, 2010).

I'm not very sure how to actually implement this manually..

Further, Stan returns the first passage time of the accumulation process over the upper boundary only. To get the result for the lower boundary, use wiener(y|α,τ,1−β,−δ) For more details, see the appendix of Vandekerckhove and Wabersich (2014).


```{r model, options}

"data {
  int<lower=1> S; // Subjects
  real y[S];
  real<lower=0> sigma[S];
}
parameters {
  real alpha; //
  real delta[S]; // drift rate
  vector[S] eta;
}
transformed parameters {
  real bias = alpha / 2;
  vector[S] theta = mu + tau * eta;
}
model {
  target += normal_lpdf(eta | 0, 1);
  target += wiener_lpdf(y | alpha, tau, beta, delta);
}
" %>%
  cat(file="STAN/diff.stan")



```












#####################
#### brms + RWiener
#####################


