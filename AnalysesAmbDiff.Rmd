---
Author: Thomas Verliefde
Date: '2019-07-10'
Output: html_document
Title: Analyses AmbDiff
editor_options:
  chunk_output_type: console
version: '0.3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
# load("20190411.RData")
# save.image(file="20190411.RData")
```

```{r libraries, include=FALSE}
lapply(
  c("plyr","dplyr","tidyr","ggplot2","readxl","readr","lme4","afex","lmerTest",
    "emmeans","purrr","magrittr","cowplot","stringr"),
  require,
  character.only = T
)
```

#################
# Data Wrangling 
#################

```{r import, cache=FALSE, message=FALSE}

temp <- tempdir()
RAW <- "Data_AmbDiff.zip" %>% {
  ldply(
    .data = unzip(.,list=T) %$%
      grep("(.csv)$",Name,value=TRUE),
    .fun = function(x) unzip(.,files=x,exdir=temp) %>%
      read_csv(col_types = rep("?",1259) %>% paste0(collapse=""))
  ) %>% as_tibble %>% arrange(Subject)
} 
rm(temp)

```

```{r !, options}

# utils::View(df_raw)
seq(1,80) %in% df_raw$Subject %>% not %>% which
"Data_AmbDiff.zip" %>% unzip(list=T) %>% arrange(Date) %>%
  filter(grepl("(.csv)$",.$Name))

```

Participant 48's data is missing ...

Comments from during data collection:
*Subject 20 was remarkably quick
*Subject 44 stated to already know the experiment - will be excluded
*Subject 59 stated to already know the experiment - will be excluded
*Subject 60 had to restart the experiment once, at the start

```{r df, options}

df <- RAW %>%
  select(
    grep("(Primes$)|(Trials$)|(^practice)",colnames(.),invert=TRUE)
  )%>%
  gather(
    key = "key",
    value = "value",
    grep("(^experiment)",colnames(.))
  ) %>%
  tidyr::extract(
    .,
    key,
    c("Block","Trial","key"),
    "(\\d+)_(\\d+)_(\\D+)$"
  ) %>%
  mutate(
    Subject = Subject %>% as.factor,
    key = key %>% str_to_title
  ) %>%
  spread(
    key,
    value
  ) %>%
  group_by(
    Subject
  ) %>%
  transmute(
    Key = Key %>% factor(levels=c("Ypos","Yneg")),
    Age = Age %>% as.numeric,
    Gender = Gender %>%
      recode(
        "weiblich" = "Female",
        "männlisch" = "Male",
        .default = "Other"
      ) %>% factor(levels=c("Female","Male","Other")),
    Language = Language %>%
      recode(
        "Deutsch" = "German",
        "Sonstiges" = "Other"
      ) %>% factor(levels=c("German","Other")),
    Handedness = Handedness %>%
      recode(
        "rechts" = "Right",
        "links" = "Left",
        "beide" = "Both"
      ) %>% factor(levels = c("Right","Left","Both")),
    Block = Block %>%
      recode(
        "0" = "First",
        "1" = "Second"
      ) %>%
      factor(levels=c("First","Second")),
    Trial = Trial %>%
      as.numeric,
    Response = case_when(
      Key == "Ypos" & Answer == "Y" ~ "Positive",
      Key == "Yneg" & Answer == "OemMinus" ~ "Positive",
      Key == "Ypos" & Answer == "OemMinus" ~ "Negative",
      Key == "Yneg" & Answer == "Y" ~ "Negative"
    ) %>%
      factor(levels = c("Positive","Negative")),
    primeWord = Prime %>% as.factor,
    primeValence = Primecat %>%
      as.factor %>%
      recode(
        "0" = "Ambivalent",
        "1" = "Positive",
        "2" = "Negative",
        "3" = "Neutral"
      ),
    targetWord = Target %>% as.factor,
    targetValence = Targetcat %>%
      as.factor %>%
      recode(
        "0" = "Positive",
        "1" = "Negative"
      ),
    Congruency = case_when(
      equals(primeValence %>% as.character,targetValence %>% as.character) ~ "Congruent",
      primeValence %>% as.character %>% is_in(c("Positive","Negative")) ~ "Incongruent",
      TRUE ~ primeValence %>% as.character
    ) %>% factor(levels=c("Ambivalent","Congruent","Incongruent","Neutral")),
    RT = Time %>% as.numeric,
    logRT = RT %>% log,
    Correct = Response == targetValence,
    Accuracy = mean(Correct),
    latencyIncl = (RT >= 300 & RT <= 3000),
    accIncl = (1 - mean(latencyIncl | Correct)) < 0.83,
    ruleIncl = (Subject %in% c(44,59,60)) %>% not,
    subjIncl = accIncl & ruleIncl,
    trialIncl = Correct & latencyIncl,
    Inclusion = trialIncl & subjIncl,
    diffInclusion = latencyIncl & subjIncl
  ) %>% ungroup %>%
  arrange(Subject,Block,Trial)

```

```{r dfDemo, options}

dfDemo <- df %>%
  distinct(Subject,Key,Age,Gender,Language,Handedness,Accuracy,accIncl,ruleIncl,subjIncl)

```

################
# Demographics 
################

```{r subj excl, options}

dfDemo %>%
  filter(accIncl %>% not) %>%
  nrow %>%
  paste("participants were excluded due to extremes in accuracy or latency.")

dfDemo %>%
  filter(ruleIncl %>% not) %>%
  nrow %>%
  paste("participants were excluded due to issues during data collection.")
# 2 participants indicated to have already performed the experiment before.
# 1 participant had to restart the program during experimentation.

dfDemo %>%
  filter(subjIncl) %>%
  nrow %>%
  paste("participants were included for the analyses.")

```

```{r trial excl, options}

df %>%
  filter(subjIncl) %$%
  mean(Correct) %>%
  subtract(1,.) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were incorrectly categorised.")

df %>%
  filter(subjIncl) %$%
  mean(latencyIncl) %>%
  subtract(1,.) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were responded to either too quickly (<300ms) or too slowly (>3000ms)")

df %>%
  filter(subjIncl) %$%
  mean(trialIncl) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were ultimately included for hierarchical analyses, based on speed and accuracy.")

df %>%
  filter(subjIncl) %$%
  mean(latencyIncl) %>%
  multiply_by(100) %>%
  signif(2) %>%
  paste0("% of trials from included participants were ultimately included for diffusion analyses, based on speed and accuracy.")

```


############
# Analyses 
############

################
## Hierarchical
################

The main idea here is to test whether the ambivalence deceleration found in previous research (e.g. Berger, Hütter, & Corneille, 2019) is also found here.
For this, we run a mixed model.


```{r Valence Model, options}

afex::set_effects_contrasts()

valFit <- df %>%
  filter(Inclusion) %>%
  mixed(
    logRT ~ primeValence * targetValence * Block + (1|primeWord) + (1|targetWord) + (1|Subject),
    data = .,
    method='S'
  )
valFit

emmValFit <- valFit %>%
  emmeans(~primeValence * targetValence)


contrValFit <- emmValFit %>%
  contrast(method="revpairwise",adjust="none") %>%
  as_tibble %>%
  separate(
    contrast,
    c("primeA","targetA","primeB","targetB")
  ) %>%
  filter(primeB == "Ambivalent" & primeA != "Ambivalent") %>%
  filter(targetA == targetB)

```

```{r Mixed Contrasts, options}

valFit %>%
  emmeans(~Block) %>%
  contrast

valFit %>%
  emmeans(~primeValence * targetValence * Block) %>%
  contrast(method = "trt.vs.ctrl", by=c("Block","targetValence"))

valFit %>%
  emmeans(~primeValence * targetValence) %>%
  contrast(method = "trt.vs.ctrl", by=c("targetValence"))


```

Block Comparison

 contrast      estimate      SE  df z.ratio p.value
 First effect     0.021 0.00178 Inf  11.789 <.0001  ***
 Second effect   -0.021 0.00178 Inf -11.789 <.0001  ***


Prime Comparison by Block & targetValence

Block = First, targetValence = Positive:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.010508 0.0101 Inf -1.044  0.5833 
 Negative - Ambivalent  0.013543 0.0102 Inf  1.328  0.4056 
 Neutral - Ambivalent   0.000555 0.0101 Inf  0.055  0.9989 

Block = First, targetValence = Negative:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.005451 0.0103 Inf -0.531  0.8819 
 Negative - Ambivalent -0.009350 0.0103 Inf -0.911  0.6692 
 Neutral - Ambivalent  -0.012950 0.0102 Inf -1.269  0.4406 

Block = Second, targetValence = Positive:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent -0.036828 0.0100 Inf -3.672  0.0007  ***
 Negative - Ambivalent  0.006738 0.0101 Inf  0.666  0.8154 
 Neutral - Ambivalent  -0.019648 0.0101 Inf -1.948  0.1325 

Block = Second, targetValence = Negative:
 contrast               estimate     SE  df z.ratio p.value
 Positive - Ambivalent  0.001699 0.0102 Inf  0.167  0.9891 
 Negative - Ambivalent -0.026018 0.0101 Inf -2.573  0.0281  *
 Neutral - Ambivalent  -0.011373 0.0101 Inf -1.124  0.5314


Prime Comparison by targetValence, averaged over Block

targetValence = Positive:
 contrast              estimate      SE  df z.ratio p.value
 Positive - Ambivalent -0.02367 0.00717 Inf -3.300  0.0028  ***
 Negative - Ambivalent  0.01014 0.00725 Inf  1.398  0.3651 
 Neutral - Ambivalent  -0.00955 0.00721 Inf -1.325  0.4073 

targetValence = Negative:
 contrast              estimate      SE  df z.ratio p.value
 Positive - Ambivalent -0.00188 0.00730 Inf -0.257  0.9734 
 Negative - Ambivalent -0.01768 0.00727 Inf -2.431  0.0414  *
 Neutral - Ambivalent  -0.01216 0.00725 Inf -1.677  0.2278 
 
We can replicate the results found previously:
  Ambivalent prime trials have significantly higher latencies in comparison to congruent positive and negative noun prime trials.
  There seems to be no difference otherwise, not for incongruent trials, nor for neutral letter primes.

These results are not found in only the first block, but they are found in the second, and when averaging over blocks.
Further, the results above are computed with the dunnettx method for 3 tests. Leaving out this adjustment, the results stay the same.

```{r emmGraph, options}

ggValFit <- emmValFit %>%
  as_tibble %>%
  transmute(
    RT = emmean %>% exp,
    minRT = asymp.LCL %>% exp,
    maxRT = asymp.UCL %>% exp,
    primeValence = primeValence %>% factor(levels = c("Ambivalent","Positive","Negative","Neutral")),
    targetValence = targetValence %>% factor(levels = c("Positive","Negative")),
    Congruency = case_when(
      equals(primeValence %>% as.character,targetValence %>% as.character) ~ "Congruent",
      TRUE ~ "Other"
      )
  ) %>%
  ggplot(
    aes(y = RT, ymin = minRT, ymax = maxRT, x = primeValence, fill = targetValence, colour = Congruency, size = if_else(Congruency == "Congruent",1.1,0))
  ) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(position = position_dodge2(padding=.8),colour="black",size=.5) +
  labs(x = "Prime Valence", y = "Reaction Times (ms)", fill = "Target\nValence") +
  guides(colour=FALSE,size=FALSE) +
  scale_colour_manual(values=c("black","white")) +
  scale_size_identity() +
  theme(
    plot.margin = unit(c(1.4,0.4,0.4,0.4),"cm")
  ) +
  geom_segment(
    data = tibble(
      x = c(.75,1.25),
      xend = c(1.75,3.25),
      y = c(660,700),
      yend = c(660,700)
    ),
    aes(x=x,y=y,xend=xend,yend=yend,size=.75),
    inherit.aes = FALSE
  ) +
  geom_label(
    data = contrValFit %>% filter(p.value < .05),
    aes(
      x = c(1.25,2.25),
      y = c(660,700),
      label = p.value %>% sprintf("%.3f",.)
    ),
    inherit.aes = FALSE
  )
ggValFit

ggsave("valEmm.svg",plot = ggValFit,device = "svg")


```

Comparisons with neutral primes did not show differences, except for incongruent negative trials.

```{r further contrasts, options}

emmValFit %>% contrast(method = "trt.vs.ctrlk", by=c("targetValence"))

```


```{r Congruency Model, options}

afex::set_effects_contrasts()

congrFit <- df %>%
  filter(Inclusion) %>%
  mixed(
    logRT ~ Congruency * Block + (1|primeWord) + (1|targetWord) + (1|Subject),
    data = .,
    method='S'
  )
congrFit

emmCongrFit <- congrFit %>%
  emmeans(~Congruency)


contrCongrFit <- emmCongrFit %>%
  contrast(method="trt.vs.ctrl",adjust="none") %>%
  as_tibble %>%
  separate(
    contrast,
    c("primeA","primeB")
  )

congrFit %>%
  emmeans(~Block) %>%
  contrast

```

Comparing directly on congruency, the same results are found, with ambivalent trials being clearly slower than congruent trials.
Note that here there seems to be a difference between neutral and ambivalent primes, indicating ambivalent primes being slower.
The inconsistency between this model and the previous could reflect the difficulty of consistently finding this effect (e.g. Berger, Hütter, & Corneille, 2019).

```{r label, options}

ggCongrFit <- emmCongrFit %>%
  as_tibble %>%
  transmute(
    RT = emmean %>% exp,
    minRT = asymp.LCL %>% exp,
    maxRT = asymp.UCL %>% exp,
    Congruency = Congruency %>% factor(levels = c("Ambivalent","Congruent","Incongruent","Neutral"))
  ) %>%
  ggplot(
    aes(y = RT, ymin = minRT, ymax = maxRT, x = Congruency)
  ) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(width=.3) +
  labs(x = "Prime Conditions", y = "Reaction Times (ms)") +
  theme(
    plot.margin = unit(c(1.4,0.4,0.4,0.4),"cm")
  ) +
  geom_segment(
    data = tibble(
      x = c(1,1),
      xend = c(2,4),
      y = c(660,700),
      yend = c(660,700)
    ),
    aes(x=x,y=y,xend=xend,yend=yend,size=1),
    inherit.aes = FALSE
  ) +
  scale_size_identity() +
  geom_label(
    data = contrCongrFit %>% filter(p.value < .05),
    aes(
      x = c(1.5,2.5),
      y = c(660,700),
      label = p.value %>% sprintf("%.4f",.)
    ),
    inherit.aes = FALSE
  )
ggCongrFit

ggsave("congrEmm.svg",plot = ggCongrFit,device = "svg")

```


###############
## Diffusion 
###############

Voss et al. 2013 - Cognitive Processses in Associative and Categorical Priming: A Diffusion Model Analysis

Parameters:
  v   drift rate
  a   thershold distance
  z   starting point
  t0  non-decisional processes
  sx  trial-to-trial variability
  
  d = t0lower - t0upper
  t0lower  non-decisional processes for lower threshold
  t0upper  non-decisional processes for upper threshold

Kolmogorov-Smirnov Statistic for optimization

The diffusion model was fitted to the individual response time distributions (using fast-dm).
In all analyses, data were collapsed across target types (i.e. positive and negative).
The upper threshold was assigned to correct responses (~ positive drift rates indicate more efficient processing).
The d-parameter maps the difference between positions of RT-distributions for correct responses and error responses.
If primes influence the speed of response execution, larger values of d will emerge for congruent primes, and smaller for incongruent primes.

Due to a low number of errors, it was not possible to estimate a model with free starting point and with separate non-decisional parameters for correct and incorrect responses.
For the same reason, the distance from the starting point to the lower threshold can also not be estimated with sufficient accuracy.
We therefore decided to fix z to a/2 in all analyses. We decided to estimate separate t0 parameters, rather than differences in starting point.

Drift rate (v), response-time constant (t0), and response tendency parameter (d) were estimated separately for different prime types (i.e., congruent, incongruent, or neutral) while the remaining parameters (a, sz, sv, and st) were assumed constant across conditions.


Overview and Hypotheses

The drift rate (v) maps effects such as differences in speed of target identification, or accessibility of semantic target features.
The response-time constant (t0) captures activation and execution of the correct motor program.

  We assume that primes lead to a pre-activation of associated target concepts and their semantic attributes which should have an impact on the efficiency of the decision process. Information from pre-activated targets should be more readily accessible, that is, the target concept and semantic target attributes should be processed and identified more readily. Therefore, we expect larger drift rates (v) for targets associated compared to non-associated primes. Such associative priming effects are expected to be largerly independent of the task that is to be performed on the targets as long as the task requires lexical or semantic target processing.
  As elaborated above, we expect that all types of response priming designs are primarily based on Stroop-like interference processes. We assume that such interference processes operate at the stage of response execution. According to this account, a prime from the same category as a following target might pre-activate the corresponding motor-response program. In this case, the primed response can be executed faster. IF the prime belongs to the alternative response category, the execution of the correct response to the target should be slowed down due to response interference. Since these effects operate independently of the identification and classification of the target, they will be mapped onto the non-decisional RT component of the diffusion model. The non-decisional component shoulde either be generally reduced by a categorical match between prime and target (lower values on t0), or, more specifically, the primes should reduce/increase the time that is need in order to execute the matching/non-matching response, leading to positive/negative values for d in case of congruent/incongruent primes
  Another possibility that cannot be ruled out a priori is that response priming effects influence the response selection process by biasing the deciison process in the direction of the prime category. Such an effect would be mapped by the diffusion model on the starting point (z). As already mentioned above, we cannot estimate priming effects on t0, d, and z simultaneously (Voss et al. 2010). We therefore decided to estimate models with two non-decisional components (t0 and d) in which the starting point was fixed, but we also conducted additional analyses in which the starting point was estimated freely.


Experiment 1b: affective priming in the evaluation task
Experiment 2a: affective congruency of prime-target pairs.


For experiment 1b, 48 positive and 48 negative German adjectives were used as targets. 48 positive and 48 negative nouns were used as primes. Prime-target pairs were constructed by assigning one congruent prime, one incongruent prime, and one neutral letter string prime to each target. Each prime word was used as congruent prime for one target and as incongruent prime for another target. Pairings were identical for all participants.
The only theoretically relevant factor was prime type: affectively congruent, affectively incongruent, neutral.

Data pre-treatment.
  Speed instructions and rewarding of speeded responses were used to evoke a high error rate. However, the logic of payoffs seemed to have encouraged participants to make fast guesses in some trials to maximize the chance of winning the performance related reward. Accordingly, there was a large amount of fast outlier latencies which can bias parameter estimates from a diffusion model analysis. Therefore, a three-step procedure to identify outliers was performed: First, all latencies below 200ms were excluded. Second, latencies were eliminated starting from the lower edge of the individual RT distributions until the number of removed correct responses exceeded the number of removed error responses by 3. This was done to exclude latencies that were based on pure guessing. Third, from the remaining individual latency distributions values below the first quartile minus 1.5 inter-quartile-ranges were eliminated, and similar for values above the third quartiel plus 1.5 inter-quartile-ranges. This procedure led to an exclusion of 7.3% of trials.

```{r Mixed Exp 1b, options}

df %>%
  filter(Inclusion) %>%
  summarize()
  


```

```{r reproduction Voss et al. 2013, options}

df %>%
  filter(diffInclusion)



```

